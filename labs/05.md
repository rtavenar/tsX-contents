# üî¨ Lab Ideas for Session 5: Structured State Space Models (SSMs)

## Lab 5.1: Classical vs. Neural State Space Models
- **Task:** Implement a classical linear state space model (e.g., Kalman filter) and compare it to a deep learning baseline (RNN/LSTM) on the same forecasting task.  
- **Focus:** Explore strengths and weaknesses: interpretability, sample efficiency, robustness to noise.  
- **Advanced Twist:** Analyze how each model handles missing or noisy observations and whether hybrid approaches improve performance.  

---

## Lab 5.2: Deep State Space Models
- **Task:** Implement a deep SSM (e.g., Deep Kalman Filter or Recurrent State Space Model).  
- **Focus:** Learn how neural networks can parameterize state transition and emission functions.  
- **Advanced Twist:** Evaluate performance on synthetic datasets with controlled dynamics (e.g., switching regimes, nonlinear transitions) to see where deep SSMs outperform classical ones.  

---

## Lab 5.3: Scaling SSMs for Long Sequences
- **Task:** Implement and train modern scalable SSMs (e.g., S4 or DSS).  
- **Focus:** Compare their efficiency and accuracy to RNNs and Transformers on long-range forecasting tasks.  
- **Advanced Twist:** Benchmark training speed, memory usage, and forecasting accuracy as sequence length grows (e.g., 10¬≥ ‚Üí 10‚Åµ timesteps).  

---

## Lab 5.4: Hybrid Models: Signal Processing Meets Deep Learning
- **Task:** Combine classical signal processing tools (e.g., Fourier or wavelet transforms) with SSM-based deep learning models.  
- **Focus:** Study whether incorporating frequency-domain priors improves model stability and forecasting.  
- **Advanced Twist:** Require students to ablate the hybrid components (with/without spectral preprocessing) and interpret why hybridization helps or fails in certain regimes.  
