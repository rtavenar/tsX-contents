{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a44b6105",
   "metadata": {},
   "source": [
    "# Time Series Classification\n",
    "\n",
    "In this lab, you will work on time series classification (TSC) tasks. You will learn how to:\n",
    "- Load the UCI HAR dataset and build PyTorch data loaders\n",
    "- Build a simple data loader for classification tasks\n",
    "- Implement TimesNet: a modern deep learning model based on 2D convolutions\n",
    "\n",
    "The lab focuses on practical implementation, allowing you to understand the key components\n",
    "of TSC models without getting lost in implementation details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f42373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9dc6f0",
   "metadata": {},
   "source": [
    "## Part 1: Data Loading\n",
    "\n",
    "In this section, you will load the UCI HAR (Human Activity Recognition) dataset\n",
    "and create a PyTorch data loader for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff70208b",
   "metadata": {},
   "source": [
    "**Question 1.** Download the UCI HAR dataset (if needed) and load the train/test arrays.\n",
    "\n",
    "- Download: `wget -O data/UCIHAR.npz https://github.com/rtavenar/ml-datasets/releases/download/UCIHAR/UCIHAR.npz`\n",
    "- Load from `.npz` — data is `(n_samples, T, C)` (time steps, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555de42d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "!wget -O data/UCIHAR.npz https://github.com/rtavenar/ml-datasets/releases/download/UCIHAR/UCIHAR.npz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad88c1e",
   "metadata": {},
   "source": [
    "**Question 2.** Implement a PyTorch `Dataset` class for time series classification.\n",
    "\n",
    "The dataset should:\n",
    "- Take numpy arrays `X` and `y` as input\n",
    "- Assume `X` has shape `(n_samples, T, C)` — samples, time steps, channels\n",
    "- Return `(time_series, label)` with `time_series` of shape `(T, C)`\n",
    "- Optionally support normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4300ada",
   "metadata": {},
   "source": [
    "## Part 2: TimesNet Model\n",
    "\n",
    "TimesNet transforms time series into 2D representations based on detected periods,\n",
    "then applies 2D convolutions. We provide two building blocks:\n",
    "\n",
    "1. **`extract_periods_and_amplitudes`** — FFT-based period detection\n",
    "2. **`PeriodReshape`** — nn.Module that reshapes `(B, T, C)` into 2D tensors given periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9e9ae2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_periods_and_amplitudes(ts, top_k=5):\n",
    "    \"\"\"\n",
    "    Extract top-k periods and their FFT amplitudes from a time series.\n",
    "    \n",
    "    Args:\n",
    "        ts: tensor of shape (T,) or (T, C) — 1D or multivariate (channels averaged for FFT)\n",
    "        top_k: number of periods to return\n",
    "    \n",
    "    Returns:\n",
    "        periods: list of int, period lengths\n",
    "        amplitudes: list of float, FFT power at each period\n",
    "    \"\"\"\n",
    "    if ts.dim() > 1:\n",
    "        ts = ts.mean(dim=-1)  # (T,)\n",
    "    ts = ts.float()\n",
    "    fft_vals = torch.fft.rfft(ts)\n",
    "    power = torch.abs(fft_vals) ** 2\n",
    "    \n",
    "    min_period, max_period = 2, len(ts) // 2\n",
    "    freqs = torch.arange(len(power), dtype=torch.float32, device=ts.device)\n",
    "    periods_float = len(ts) / (freqs + 1e-8)\n",
    "    \n",
    "    valid = (periods_float >= min_period) & (periods_float <= max_period)\n",
    "    pwr, prd = power[valid], periods_float[valid]\n",
    "    if len(pwr) == 0:\n",
    "        return [len(ts) // 2], [1.0]\n",
    "    \n",
    "    k = min(top_k, len(pwr))\n",
    "    vals, idx = torch.topk(pwr, k)\n",
    "    return prd[idx].int().tolist(), vals.tolist()\n",
    "\n",
    "\n",
    "class PeriodReshape(nn.Module):\n",
    "    \"\"\"\n",
    "    Reshape multivariate time series (B, T, C) into 2D tensors per period.\n",
    "    Output: list of tensors of shape (B, C, period, num_periods).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, periods):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            periods: list or tensor of int, period lengths to use\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.periods = [int(p) for p in periods]\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (B, T, C) — batch of multivariate time series\n",
    "        Returns:\n",
    "            list of (B, C, period, num_periods) tensors, one per period\n",
    "        \"\"\"\n",
    "        B, T, C = x.shape\n",
    "        out = []\n",
    "        for p in self.periods:\n",
    "            n = (T + p - 1) // p\n",
    "            need = n * p\n",
    "            if need > T:\n",
    "                xp = torch.nn.functional.pad(x, (0, 0, 0, need - T))\n",
    "            else:\n",
    "                xp = x[:, :need]\n",
    "            # (B, T', C) -> (B, C, p, n)\n",
    "            out.append(xp.permute(0, 2, 1).reshape(B, C, p, n))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7ff5a5",
   "metadata": {},
   "source": [
    "**Question 3.** Use `extract_periods_and_amplitudes` on a sample to get periods, then\n",
    "use `PeriodReshape` to obtain 2D representations. Visualize one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d137a660",
   "metadata": {},
   "source": [
    "**Question 4.** Implement a TimesNet model for classification.\n",
    "\n",
    "Use `PeriodReshape` and implement:\n",
    "- 2D convolutional blocks on each period’s representation\n",
    "- Global pooling, feature aggregation, and a classification head\n",
    "\n",
    "Hint: periods can be fixed (e.g. from `extract_periods_and_amplitudes` on training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87db386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimesNetBlock(nn.Module):\n",
    "    \"\"\"2D conv block on period-reshaped data. in_channels = C (input channels).\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels=64, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size // 2),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size, padding=kernel_size // 2),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a9f9f9",
   "metadata": {},
   "source": [
    "**Question 5.** Train and evaluate the TimesNet model using the loops provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74483d1c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, criterion, device='cpu'):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for ts, labels in dataloader:\n",
    "        ts, labels = ts.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(ts)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * ts.size(0)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += (pred == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_epoch(model, dataloader, criterion, device='cpu'):\n",
    "    \"\"\"Evaluate for one epoch.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for ts, labels in dataloader:\n",
    "        ts, labels = ts.to(device), labels.to(device)\n",
    "        \n",
    "        logits = model(ts)\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        total_loss += loss.item() * ts.size(0)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += (pred == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "def train_classif_model(model, train_loader, test_loader, n_epochs=50, lr=1e-3, device='cpu'):\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_losses, train_accs = [], []\n",
    "    test_losses, test_accs = [], []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        test_loss, test_acc = eval_epoch(model, test_loader, criterion, device)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accs.append(test_acc)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "            print(f\"Epoch {epoch+1:3d} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "                  f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'train_loss': train_losses,\n",
    "        'train_acc': train_accs,\n",
    "        'test_loss': test_losses,\n",
    "        'test_acc': test_accs\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb745b3",
   "metadata": {},
   "source": [
    "**Question 6.** In the TimesNet paper, the authors suggest using a **weighted average** for\n",
    "aggregating period features instead of concatenation: the weights are a softmax over the\n",
    "period amplitudes (higher FFT power → higher weight).\n",
    "\n",
    "Implement an alternative `TimesNetAmplitudeWeighted` model that:\n",
    "- Takes `periods` and `amplitudes` (from `extract_periods_and_amplitudes`) at init\n",
    "- Pools each period's features to `(B, hidden_dim)` as before\n",
    "- Aggregates them with a **softmax-weighted average**: weights = softmax(amplitudes)\n",
    "- Uses a classifier on the aggregated `(B, hidden_dim)` representation\n",
    "\n",
    "Train and compare its test accuracy with the standard TimesNet from Question 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b6b8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get amplitudes from reference (same as for periods)\n",
    "_ref_ts = torch.from_numpy(X_train.mean(axis=0)).float()\n",
    "periods_aw, amplitudes_aw = extract_periods_and_amplitudes(_ref_ts, top_k=3)\n",
    "\n",
    "model_aw = TimesNetAmplitudeWeighted(\n",
    "    n_channels=n_channels,\n",
    "    num_classes=num_classes,\n",
    "    periods=periods_aw,\n",
    "    amplitudes=amplitudes_aw,\n",
    "    hidden_dim=64,\n",
    "    num_blocks=2,\n",
    ")\n",
    "\n",
    "print(\"Training TimesNetAmplitudeWeighted...\")\n",
    "logs_aw = train_classif_model(model_aw, train_loader, test_loader, n_epochs=5, lr=1e-3, device=device)\n",
    "\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"TimesNet (concat):        Test Acc = {logs['test_acc'][-1]:.4f}\")\n",
    "print(f\"TimesNet (amplitude-wtd): Test Acc = {logs_aw['test_acc'][-1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
