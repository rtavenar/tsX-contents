{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a44b6105",
   "metadata": {},
   "source": [
    "# Time Series Classification\n",
    "\n",
    "In this lab, you will work on time series classification (TSC) tasks. You will learn how to:\n",
    "- Load the UCI HAR dataset and build PyTorch data loaders\n",
    "- Build a simple data loader for classification tasks\n",
    "- Implement TimesNet: a modern deep learning model based on 2D convolutions\n",
    "\n",
    "The lab focuses on practical implementation, allowing you to understand the key components\n",
    "of TSC models without getting lost in implementation details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f42373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9dc6f0",
   "metadata": {},
   "source": [
    "## Part 1: Data Loading\n",
    "\n",
    "In this section, you will load the UCI HAR (Human Activity Recognition) dataset\n",
    "and create a PyTorch data loader for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff70208b",
   "metadata": {},
   "source": [
    "**Question 1.** Download the UCI HAR dataset (if needed) and load the train/test arrays.\n",
    "\n",
    "- Download: `wget -O data/UCIHAR.npz https://github.com/rtavenar/ml-datasets/releases/download/UCIHAR/UCIHAR.npz`\n",
    "- Load from `.npz` — data is `(n_samples, T, C)` (time steps, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555de42d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "!wget -O data/UCIHAR.npz https://github.com/rtavenar/ml-datasets/releases/download/UCIHAR/UCIHAR.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af115c2",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "solution"
    ],
    "title": "+"
   },
   "outputs": [],
   "source": [
    "dataset = numpy.load(\"data/UCIHAR.npz\")\n",
    "X_train, y_train = dataset[\"X_train\"], dataset[\"y_train\"].ravel()\n",
    "X_test, y_test = dataset[\"X_test\"], dataset[\"y_test\"].ravel()\n",
    "\n",
    "print(f\"Dataset: UCI HAR — X shape (n_samples, T, C): {X_train.shape}\")\n",
    "print(f\"Train labels: {numpy.unique(y_train)}, Classes: {len(numpy.unique(y_train))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad88c1e",
   "metadata": {},
   "source": [
    "**Question 2.** Implement a PyTorch `Dataset` class for time series classification.\n",
    "\n",
    "The dataset should:\n",
    "- Take numpy arrays `X` and `y` as input\n",
    "- Assume `X` has shape `(n_samples, T, C)` — samples, time steps, channels\n",
    "- Return `(time_series, label)` with `time_series` of shape `(T, C)`\n",
    "- Optionally support normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e975ccc5",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "solution"
    ],
    "title": "+"
   },
   "outputs": [],
   "source": [
    "class TSCDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Time Series Classification Dataset. Expects X of shape (n_samples, T, C).\"\"\"\n",
    "    \n",
    "    def __init__(self, X, y, normalize=True, scaler=None):\n",
    "        super().__init__()\n",
    "        self.X = X.astype(numpy.float32)\n",
    "        self.y = y.astype(numpy.int64)\n",
    "        self.normalize = normalize\n",
    "        if normalize:\n",
    "            self.scaler = scaler or StandardScaler()\n",
    "            if scaler is None:\n",
    "                self.scaler.fit(self.X.reshape(-1, 1))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ts = self.X[idx]  # (T, C)\n",
    "        if self.normalize:\n",
    "            ts = self.scaler.transform(ts.reshape(-1, 1)).reshape(ts.shape)\n",
    "        return torch.from_numpy(ts), torch.tensor(self.y[idx], dtype=torch.long)\n",
    "\n",
    "# Create datasets and data loaders (fit scaler on train only)\n",
    "train_dataset = TSCDataset(X_train, y_train, normalize=True)\n",
    "test_dataset = TSCDataset(X_test, y_test, normalize=True, scaler=train_dataset.scaler)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=32, shuffle=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=32, shuffle=False\n",
    ")\n",
    "\n",
    "# Verify shapes\n",
    "sample_ts, sample_label = train_dataset[0]\n",
    "print(f\"Sample time series shape: {sample_ts.shape}\")\n",
    "print(f\"Sample label: {sample_label.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4300ada",
   "metadata": {},
   "source": [
    "## Part 2: TimesNet Model\n",
    "\n",
    "TimesNet transforms time series into 2D representations based on detected periods,\n",
    "then applies 2D convolutions. We provide two building blocks:\n",
    "\n",
    "1. **`extract_periods_and_amplitudes`** — FFT-based period detection\n",
    "2. **`PeriodReshape`** — nn.Module that reshapes `(B, T, C)` into 2D tensors given periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9e9ae2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_periods_and_amplitudes(ts, top_k=5):\n",
    "    \"\"\"\n",
    "    Extract top-k periods and their FFT amplitudes from a time series.\n",
    "    \n",
    "    Args:\n",
    "        ts: tensor of shape (T,) or (T, C) — 1D or multivariate (channels averaged for FFT)\n",
    "        top_k: number of periods to return\n",
    "    \n",
    "    Returns:\n",
    "        periods: list of int, period lengths\n",
    "        amplitudes: list of float, FFT power at each period\n",
    "    \"\"\"\n",
    "    if ts.dim() > 1:\n",
    "        ts = ts.mean(dim=-1)  # (T,)\n",
    "    ts = ts.float()\n",
    "    fft_vals = torch.fft.rfft(ts)\n",
    "    power = torch.abs(fft_vals) ** 2\n",
    "    \n",
    "    min_period, max_period = 2, len(ts) // 2\n",
    "    freqs = torch.arange(len(power), dtype=torch.float32, device=ts.device)\n",
    "    periods_float = len(ts) / (freqs + 1e-8)\n",
    "    \n",
    "    valid = (periods_float >= min_period) & (periods_float <= max_period)\n",
    "    pwr, prd = power[valid], periods_float[valid]\n",
    "    if len(pwr) == 0:\n",
    "        return [len(ts) // 2], [1.0]\n",
    "    \n",
    "    k = min(top_k, len(pwr))\n",
    "    vals, idx = torch.topk(pwr, k)\n",
    "    return prd[idx].int().tolist(), vals.tolist()\n",
    "\n",
    "\n",
    "class PeriodReshape(nn.Module):\n",
    "    \"\"\"\n",
    "    Reshape multivariate time series (B, T, C) into 2D tensors per period.\n",
    "    Output: list of tensors of shape (B, C, period, num_periods).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, periods):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            periods: list or tensor of int, period lengths to use\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.periods = [int(p) for p in periods]\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (B, T, C) — batch of multivariate time series\n",
    "        Returns:\n",
    "            list of (B, C, period, num_periods) tensors, one per period\n",
    "        \"\"\"\n",
    "        B, T, C = x.shape\n",
    "        out = []\n",
    "        for p in self.periods:\n",
    "            n = (T + p - 1) // p\n",
    "            need = n * p\n",
    "            if need > T:\n",
    "                xp = torch.nn.functional.pad(x, (0, 0, 0, need - T))\n",
    "            else:\n",
    "                xp = x[:, :need]\n",
    "            # (B, T', C) -> (B, C, p, n)\n",
    "            out.append(xp.permute(0, 2, 1).reshape(B, C, p, n))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7ff5a5",
   "metadata": {},
   "source": [
    "**Question 3.** Use `extract_periods_and_amplitudes` on a sample to get periods, then\n",
    "use `PeriodReshape` to obtain 2D representations. Visualize one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fed585f",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "solution"
    ],
    "title": "+"
   },
   "outputs": [],
   "source": [
    "sample_ts = train_dataset[0][0]  # (T, C)\n",
    "periods, amplitudes = extract_periods_and_amplitudes(sample_ts, top_k=3)\n",
    "print(f\"Detected periods: {periods}, amplitudes: {amplitudes}\")\n",
    "\n",
    "reshape_module = PeriodReshape(periods)\n",
    "# Add batch dim: (T, C) -> (1, T, C)\n",
    "reps = reshape_module(sample_ts.unsqueeze(0))\n",
    "for i, r in enumerate(reps):\n",
    "    print(f\"Period {periods[i]}: 2D shape {r.shape}\")\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(reps[0][0].mean(0).numpy(), aspect='auto', cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.title(f\"2D Representation (Period {periods[0]})\")\n",
    "plt.xlabel(\"Period index\")\n",
    "plt.ylabel(\"Time within period\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d137a660",
   "metadata": {},
   "source": [
    "**Question 4.** Implement a TimesNet model for classification.\n",
    "\n",
    "Use `PeriodReshape` and implement:\n",
    "- 2D convolutional blocks on each period’s representation\n",
    "- Global pooling, feature aggregation, and a classification head\n",
    "\n",
    "Hint: periods can be fixed (e.g. from `extract_periods_and_amplitudes` on training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87db386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimesNetBlock(nn.Module):\n",
    "    \"\"\"2D conv block on period-reshaped data. in_channels = C (input channels).\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels=64, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size // 2),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size, padding=kernel_size // 2),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f10d3a4",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "solution"
    ],
    "title": "+"
   },
   "outputs": [],
   "source": [
    "class TimesNet(nn.Module):\n",
    "    \"\"\"TimesNet for classification. Uses fixed periods and PeriodReshape.\"\"\"\n",
    "\n",
    "    def __init__(self, n_channels, num_classes, periods, hidden_dim=64, num_blocks=2):\n",
    "        super().__init__()\n",
    "        self.reshape = PeriodReshape(periods)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            nn.Sequential(*[\n",
    "                TimesNetBlock(\n",
    "                    in_channels=n_channels if i == 0 else hidden_dim,\n",
    "                    out_channels=hidden_dim,\n",
    "                    kernel_size=3,\n",
    "                )\n",
    "                for i in range(num_blocks)\n",
    "            ])\n",
    "            for _ in periods\n",
    "        ])\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * len(periods), hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        reps = self.reshape(x)  # list of (B, C, p, n)\n",
    "        feats = []\n",
    "        for r, blk in zip(reps, self.blocks):\n",
    "            h = blk(r)\n",
    "            feats.append(self.pool(h).flatten(1))\n",
    "        out = torch.cat(feats, dim=1)\n",
    "        return self.classifier(out)\n",
    "\n",
    "\n",
    "# Compute periods once from training data\n",
    "_ref_ts = torch.from_numpy(X_train.mean(axis=0)).float()  # (T, C)\n",
    "periods, _ = extract_periods_and_amplitudes(_ref_ts, top_k=3)\n",
    "num_classes = len(numpy.unique(y_train))\n",
    "n_channels = X_train.shape[2]\n",
    "\n",
    "model = TimesNet(\n",
    "    n_channels=n_channels,\n",
    "    num_classes=num_classes,\n",
    "    periods=periods,\n",
    "    hidden_dim=64,\n",
    "    num_blocks=2,\n",
    ")\n",
    "\n",
    "# Test forward pass\n",
    "sample_batch, _ = next(iter(train_loader))\n",
    "with torch.no_grad():\n",
    "    logits = model(sample_batch)\n",
    "    print(f\"Input shape: {sample_batch.shape}\")\n",
    "    print(f\"Output logits shape: {logits.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a9f9f9",
   "metadata": {},
   "source": [
    "**Question 5.** Train and evaluate the TimesNet model using the loops provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74483d1c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, criterion, device='cpu'):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for ts, labels in dataloader:\n",
    "        ts, labels = ts.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(ts)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * ts.size(0)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += (pred == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_epoch(model, dataloader, criterion, device='cpu'):\n",
    "    \"\"\"Evaluate for one epoch.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for ts, labels in dataloader:\n",
    "        ts, labels = ts.to(device), labels.to(device)\n",
    "        \n",
    "        logits = model(ts)\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        total_loss += loss.item() * ts.size(0)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += (pred == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "def train_classif_model(model, train_loader, test_loader, n_epochs=50, lr=1e-3, device='cpu'):\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_losses, train_accs = [], []\n",
    "    test_losses, test_accs = [], []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        test_loss, test_acc = eval_epoch(model, test_loader, criterion, device)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accs.append(test_acc)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "            print(f\"Epoch {epoch+1:3d} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "                  f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'train_loss': train_losses,\n",
    "        'train_acc': train_accs,\n",
    "        'test_loss': test_losses,\n",
    "        'test_acc': test_accs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6074d040",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "solution"
    ],
    "title": "+"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Train model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "logs = train_classif_model(model, train_loader, test_loader, n_epochs=5, lr=1e-3, device=device)\n",
    "\n",
    "# Plot training curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(logs['train_loss'], label='Train Loss')\n",
    "plt.plot(logs['test_loss'], label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Test Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(logs['train_acc'], label='Train Accuracy')\n",
    "plt.plot(logs['test_acc'], label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Test Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Final results\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"TimesNet - Test Accuracy: {logs['test_acc'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb745b3",
   "metadata": {},
   "source": [
    "**Question 6.** In the TimesNet paper, the authors suggest using a **weighted average** for\n",
    "aggregating period features instead of concatenation: the weights are a softmax over the\n",
    "period amplitudes (higher FFT power → higher weight).\n",
    "\n",
    "Implement an alternative `TimesNetAmplitudeWeighted` model that:\n",
    "- Takes `periods` and `amplitudes` (from `extract_periods_and_amplitudes`) at init\n",
    "- Pools each period's features to `(B, hidden_dim)` as before\n",
    "- Aggregates them with a **softmax-weighted average**: weights = softmax(amplitudes)\n",
    "- Uses a classifier on the aggregated `(B, hidden_dim)` representation\n",
    "\n",
    "Train and compare its test accuracy with the standard TimesNet from Question 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcad3d39",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "solution"
    ],
    "title": "+"
   },
   "outputs": [],
   "source": [
    "class TimesNetAmplitudeWeighted(nn.Module):\n",
    "    \"\"\"TimesNet with amplitude-weighted aggregation instead of concatenation.\"\"\"\n",
    "\n",
    "    def __init__(self, n_channels, num_classes, periods, amplitudes, hidden_dim=64, num_blocks=2):\n",
    "        super().__init__()\n",
    "        self.reshape = PeriodReshape(periods)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            nn.Sequential(*[\n",
    "                TimesNetBlock(\n",
    "                    in_channels=n_channels if i == 0 else hidden_dim,\n",
    "                    out_channels=hidden_dim,\n",
    "                    kernel_size=3,\n",
    "                )\n",
    "                for i in range(num_blocks)\n",
    "            ])\n",
    "            for _ in periods\n",
    "        ])\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        # Softmax over amplitudes as fixed weights (buffer = non-trainable, moves with model)\n",
    "        amps = torch.tensor(amplitudes, dtype=torch.float32)\n",
    "        self.register_buffer(\"weights\", torch.softmax(amps, dim=0))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        reps = self.reshape(x)\n",
    "        feats = []\n",
    "        for r, blk in zip(reps, self.blocks):\n",
    "            h = blk(r)\n",
    "            feats.append(self.pool(h).flatten(1))  # (B, hidden_dim)\n",
    "        # Weighted average: (B, hidden_dim)\n",
    "        stacked = torch.stack(feats, dim=1)  # (B, n_periods, hidden_dim)\n",
    "        out = (stacked * self.weights.view(1, -1, 1)).sum(dim=1)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b6b8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get amplitudes from reference (same as for periods)\n",
    "_ref_ts = torch.from_numpy(X_train.mean(axis=0)).float()\n",
    "periods_aw, amplitudes_aw = extract_periods_and_amplitudes(_ref_ts, top_k=3)\n",
    "\n",
    "model_aw = TimesNetAmplitudeWeighted(\n",
    "    n_channels=n_channels,\n",
    "    num_classes=num_classes,\n",
    "    periods=periods_aw,\n",
    "    amplitudes=amplitudes_aw,\n",
    "    hidden_dim=64,\n",
    "    num_blocks=2,\n",
    ")\n",
    "\n",
    "print(\"Training TimesNetAmplitudeWeighted...\")\n",
    "logs_aw = train_classif_model(model_aw, train_loader, test_loader, n_epochs=5, lr=1e-3, device=device)\n",
    "\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"TimesNet (concat):        Test Acc = {logs['test_acc'][-1]:.4f}\")\n",
    "print(f\"TimesNet (amplitude-wtd): Test Acc = {logs_aw['test_acc'][-1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
