{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbb48b66",
   "metadata": {},
   "source": [
    "# Time Series Foundation Models\n",
    "\n",
    "In this lab, you will compare foundation-model-based approaches for time series\n",
    "classification and forecasting. You will:\n",
    "- Use **MANTIS** (a lightweight TSC foundation model) and **MultiROCKET** (a fast\n",
    "  feature-based baseline) on a classification task\n",
    "- Use **TiReX** for probabilistic forecasting on the ETTh dataset and visualize\n",
    "  predictions with uncertainty intervals\n",
    "\n",
    "Data loaders and setup steps are provided below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f45b22",
   "metadata": {},
   "source": [
    "## Part 0: Setup\n",
    "\n",
    "**Question 0.** Install the required packages: `mantis-tsfm` (MANTIS), `aeon`\n",
    "(MultiROCKET and data utilities), and `tirex-ts` (TiReX forecaster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43e9fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mantis-tsfm aeon tirex-ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf97d789",
   "metadata": {},
   "source": [
    "## Part 1: Time Series Classification\n",
    "\n",
    "In this part you will compare MANTIS and MultiROCKET on the UCI HAR dataset,\n",
    "then optionally combine their features.\n",
    "\n",
    "**Question 1.** Download the UCI HAR classification dataset (if needed) and\n",
    "prepare the train/test arrays. Use the code below so that `X_train`, `y_train`,\n",
    "`X_test`, `y_test` are available with shapes suitable for the classifiers\n",
    "(e.g. `X_*` of shape `(n_samples, n_channels, n_timesteps)` for aeon/MANTIS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf1f78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O data/UCIHAR.npz https://github.com/rtavenar/ml-datasets/releases/download/UCIHAR/UCIHAR.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8970c14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dataset = np.load(\"data/UCIHAR.npz\")\n",
    "\n",
    "X_train, y_train = dataset[\"X_train\"], dataset[\"y_train\"]\n",
    "X_test, y_test = dataset[\"X_test\"], dataset[\"y_test\"]\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8db15ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.swapaxes(1, 2)\n",
    "y_train = y_train.ravel()\n",
    "X_test = X_test.swapaxes(1, 2)\n",
    "y_test = y_test.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34a4a71",
   "metadata": {},
   "source": [
    "**Question 2.** Use **MANTIS** from the `mantis-tsfm` module: load the pre-trained\n",
    "Mantis8M model, extract embeddings on the training and test sets with `transform`,\n",
    "then train a linear classifier (e.g. logistic regression) on the extracted features\n",
    "and report test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d1c384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mantis.architecture import Mantis8M\n",
    "from mantis.trainer import MantisTrainer\n",
    "\n",
    "network = Mantis8M(device=\"cpu\")\n",
    "network = network.from_pretrained(\"paris-noah/Mantis-8M\")\n",
    "\n",
    "model_mantis = MantisTrainer(network=network, device=\"cpu\")\n",
    "# model_mantis.fit(X_train, y_train.flatten(), num_epochs=10, fine_tuning_type=\"head\")\n",
    "# y_pred = model_mantis.predict(X_test)\n",
    "Z_train_mantis = model_mantis.transform(X_train)\n",
    "Z_test_mantis = model_mantis.transform(X_test)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(l1_ratio=1., random_state=0).fit(Z_train_mantis, y_train)\n",
    "clf.score(Z_test_mantis, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3767bd",
   "metadata": {},
   "source": [
    "**Question 3.** Use **MultiROCKET** from the `aeon` library: fit the MultiRocket\n",
    "transformer on the training set, extract features on train and test, train a\n",
    "linear classifier on these features, and report test accuracy. Compare this\n",
    "accuracy with the one obtained with MANTIS in Question 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e13f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeon.transformations.collection.convolution_based import MultiRocket\n",
    "\n",
    "model_mr = MultiRocket(n_kernels=512)\n",
    "Z_train_mr = model_mr.fit_transform(X_train)\n",
    "clf = LogisticRegression(l1_ratio=1., random_state=0).fit(Z_train_mr, y_train)\n",
    "\n",
    "Z_test_mr = model_mr.transform(X_test)\n",
    "clf.score(Z_test_mr, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c6fa3b",
   "metadata": {},
   "source": [
    "**Question 4.** Concatenate the MANTIS and MultiROCKET feature vectors and train a linear classifier on the\n",
    "combined features. Does combining both representations improve test accuracy\n",
    "compared to using either one alone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff8713c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "Z_train_concat = np.concatenate((Z_train_mantis, Z_train_mr), axis=1)\n",
    "Z_test_concat = np.concatenate((Z_test_mantis, Z_test_mr), axis=1)\n",
    "clf = LogisticRegression(random_state=0).fit(Z_train_concat, y_train)\n",
    "clf.score(Z_test_concat, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d63b53c",
   "metadata": {},
   "source": [
    "## Part 2: Probabilistic Forecasting with TiReX\n",
    "\n",
    "In this part you will use the **TiReX** foundation model for time series\n",
    "forecasting on the univariate ETTh1 series and visualize probabilistic\n",
    "predictions.\n",
    "\n",
    "**Question 5.** Build a windowed forecasting dataset and DataLoader for ETTh1\n",
    "(e.g. context length 96, horizon 96). Load the pre-trained TiReX model from\n",
    "the `tirex-ts` module and produce probabilistic forecasts (e.g. mean and\n",
    "quantiles) on a batch of windows. Plot the past observations, ground-truth\n",
    "future, mean prediction, and uncertainty interval (e.g. 90%) for a few samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29e2ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class ForecastingDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Windowed univariate forecasting dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 csv_path: str, \n",
    "                 window: int, \n",
    "                 horizon: int, \n",
    "                 target_col: int = -1):\n",
    "        super().__init__()\n",
    "        raw = np.loadtxt(csv_path, delimiter=\",\", skiprows=1, usecols=target_col)\n",
    "        series = raw.astype(np.float32)\n",
    "        self.window = window\n",
    "        self.horizon = horizon\n",
    "        self.series = series\n",
    "        self.max_start = len(series) - window - horizon + 1\n",
    "        if self.max_start < 1:\n",
    "            raise ValueError(\"Window + horizon larger than available series length\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.max_start\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        start = idx\n",
    "        past = self.series[start : start + self.window]\n",
    "        future = self.series[start + self.window : start + self.window + self.horizon]\n",
    "        past = torch.from_numpy(past)  # shape: (window,)\n",
    "        future = torch.from_numpy(future)  # shape: (horizon,)\n",
    "        return past, future\n",
    "\n",
    "\n",
    "def build_dataloader(csv_path: str, \n",
    "                     window: int, \n",
    "                     horizon: int, \n",
    "                     batch_size: int = 32, \n",
    "                     shuffle: bool = True):\n",
    "    \"\"\"Create a DataLoader emitting `(past, horizon)` batches.\"\"\"\n",
    "    dataset = ForecastingDataset(csv_path=csv_path, \n",
    "                                 window=window, \n",
    "                                 horizon=horizon)\n",
    "    return torch.utils.data.DataLoader(dataset, \n",
    "                                       batch_size=batch_size, \n",
    "                                       shuffle=shuffle, \n",
    "                                       drop_last=False)\n",
    "dataloader = build_dataloader(\"data/ETTh1.csv\", window=96, horizon=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da7ba31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tirex import load_model, ForecastModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model: ForecastModel = load_model(\"NX-AI/TiRex\")\n",
    "\n",
    "def visualize_probabilistic_forecast(model, dataloader, n_samples=3):\n",
    "    \"\"\"Visualize probabilistic forecasts with uncertainty intervals.\"\"\"\n",
    "    model.eval()\n",
    "    past, future = next(iter(dataloader))\n",
    "    with torch.no_grad():\n",
    "        quantiles, mean = model.forecast(past, prediction_length=future.shape[1])\n",
    "        print(quantiles.shape, mean.shape)\n",
    "    \n",
    "    for i in range(min(n_samples, past.shape[0])):\n",
    "        # Plot past\n",
    "        t_past = np.arange(past.shape[1])\n",
    "        plt.plot(t_past, past[i].numpy(), 'b-', linewidth=2, label='Past observations')\n",
    "        \n",
    "        # Plot future\n",
    "        t_future = np.arange(past.shape[1], past.shape[1] + future.shape[1])\n",
    "        plt.plot(t_future, future[i].numpy(), 'g-', linewidth=2, label='Ground truth')\n",
    "        \n",
    "        # Plot mean prediction\n",
    "        plt.plot(t_future, mean[i].numpy(), 'r--', linewidth=2, label='Mean prediction')\n",
    "        \n",
    "        # Plot uncertainty bands\n",
    "        plt.fill_between(t_future, quantiles[i, :, 0].numpy(), quantiles[i, :, -1].numpy(), alpha=0.2, color='red', label='80% interval')\n",
    "        \n",
    "        plt.axvline(x=past.shape[1]-0.5, color='gray', linestyle=':', alpha=0.5)\n",
    "        plt.legend()\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title(f'Probabilistic Forecast (Sample {i+1})')\n",
    "        plt.show()\n",
    "\n",
    "visualize_probabilistic_forecast(model, dataloader, n_samples=3)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
