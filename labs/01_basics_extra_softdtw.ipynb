{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7017eb57",
   "metadata": {},
   "source": [
    "# A toy example of using softDTW as a loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f117af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tslearn.datasets import CachedDatasets\n",
    "from tslearn.metrics import SoftDTWLossPyTorch\n",
    "\n",
    "data_loader = CachedDatasets()\n",
    "X_train, y_train, X_test, y_test = data_loader.load_dataset(\"Trace\")\n",
    "\n",
    "X_subset = X_train[y_train < 4]\n",
    "np.random.shuffle(X_subset)\n",
    "X_subset = X_subset[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9f8de4",
   "metadata": {},
   "source": [
    "**Question.** Plot the time series in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250095a6",
   "metadata": {},
   "source": [
    "**Question.** In the following, we will try to predict the end of the time series based on the first 150 time points. What do you observe? Prepare a dataloader for this forecasting problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521c8308",
   "metadata": {},
   "source": [
    "**Question.** Now, compare two MLP models for the forecasting task at hand, using the same architecture for both models, but optimizing one on MSE and the other on softDTW.\n",
    "Compare the forecast quality, both qualitatively and quantitatively."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,tags,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
