{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a7de926",
   "metadata": {},
   "source": [
    "# A toy example of using softDTW as a loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654cd0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tslearn.datasets import CachedDatasets\n",
    "from tslearn.metrics import SoftDTWLossPyTorch\n",
    "\n",
    "data_loader = CachedDatasets()\n",
    "X_train, y_train, X_test, y_test = data_loader.load_dataset(\"Trace\")\n",
    "\n",
    "X_subset = X_train[y_train < 4]\n",
    "np.random.shuffle(X_subset)\n",
    "X_subset = X_subset[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb63525f",
   "metadata": {},
   "source": [
    "**Question.** Plot the time series in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca6d319",
   "metadata": {
    "tags": [
     "solution"
    ],
    "title": "+"
   },
   "outputs": [],
   "source": [
    "for ts in X_subset:\n",
    "    plt.plot(ts[:, 0], color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e8b702",
   "metadata": {},
   "source": [
    "**Question.** In the following, we will try to predict the end of the time series based on the first 150 time points. What do you observe? Prepare a dataloader for this forecasting problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150ff269",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "solution"
    ],
    "title": "+"
   },
   "outputs": [],
   "source": [
    "X_input = torch.tensor(X_subset[:, :150], dtype=torch.float32)\n",
    "y_target = torch.tensor(X_subset[:, 150:], dtype=torch.float32)\n",
    "\n",
    "batch_size = 16\n",
    "train_ds = TensorDataset(X_input, y_target)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b877fc34",
   "metadata": {},
   "source": [
    "**Question.** Now, compare two MLP models for the forecasting task at hand, using the same architecture for both models, but optimizing one on MSE and the other on softDTW.\n",
    "Compare the forecast quality, both qualitatively and quantitatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514edc3b",
   "metadata": {
    "tags": [
     "solution"
    ],
    "title": "+"
   },
   "outputs": [],
   "source": [
    "class SimpleMLP(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, output_size):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.squeeze(-1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x.unsqueeze(dim=-1)\n",
    "\n",
    "\n",
    "mse_model = SimpleMLP(150, 256, 125)\n",
    "sdtw_model = SimpleMLP(150, 256, 125)\n",
    "\n",
    "\n",
    "def train_model(model, loader, criterion, epochs=200, lr=1e-3, device=\"cpu\"):\n",
    "    model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    losses = []\n",
    "    for _ in range(epochs):\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            pred = model(xb)\n",
    "            if isinstance(criterion, torch.nn.MSELoss):\n",
    "                loss = criterion(pred.squeeze(-1), yb.squeeze(-1))\n",
    "            else:\n",
    "                loss = criterion(pred, yb)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            losses.append(loss.item())\n",
    "    return losses\n",
    "\n",
    "\n",
    "mse_losses = train_model(mse_model, train_loader, torch.nn.MSELoss(), epochs=200, lr=1e-3)\n",
    "sdtw_losses = train_model(\n",
    "    sdtw_model,\n",
    "    train_loader,\n",
    "    SoftDTWLossPyTorch(gamma=0.1, normalize=True),\n",
    "    epochs=200,\n",
    "    lr=1e-3,\n",
    ")\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X_input).squeeze(-1).numpy()\n",
    "    mse = np.mean((preds - y_target.squeeze(-1).numpy()) ** 2)\n",
    "    return preds, mse\n",
    "\n",
    "\n",
    "mse_pred, mse_score = evaluate(mse_model)\n",
    "sdtw_pred, sdtw_score = evaluate(sdtw_model)\n",
    "\n",
    "print(f\"MSE-trained model MSE: {mse_score:.4f}\")\n",
    "print(f\"softDTW-trained model MSE (eval metric is MSE): {sdtw_score:.4f}\")\n",
    "\n",
    "# Qualitative comparison on a few series\n",
    "for idx in [0, 1, 2]:\n",
    "    plt.figure(figsize=(7, 3))\n",
    "    plt.plot(range(150), X_subset[idx, :150, 0], label=\"input (first 150)\")\n",
    "    plt.plot(range(150, 275), y_target[idx, :, 0], label=\"true tail\")\n",
    "    plt.plot(range(150, 275), mse_pred[idx], label=\"MSE pred\")\n",
    "    plt.plot(range(150, 275), sdtw_pred[idx], label=\"softDTW pred\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Series {idx}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
